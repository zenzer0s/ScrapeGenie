# **ğŸ§â€â™‚ï¸ ScrapeGenie - Intelligent URL Scraper & Telegram Bot**

ScrapeGenie is a powerful **URL scraping system with Telegram integration** that intelligently extracts rich metadata from **YouTube, Instagram, and general websites**. The backend leverages **Puppeteer and Axios** for efficient web scraping, while the Telegram bot delivers beautifully formatted results with interactive inline actions.

![ScrapeGenie Banner](https://via.placeholder.com/800x200?text=ScrapeGenie)

## **ğŸš€ Features**

âœ… **Multi-Platform Scraping Engine** - Extracts content from YouTube, Instagram, and general websites  
âœ… **Rich Metadata Extraction** - Titles, descriptions, thumbnails, author information, and more  
âœ… **Resource-Optimized Architecture** - Browser instance pooling and reuse for improved performance  
âœ… **Elegant Telegram Interface** - Clean formatting with inline buttons for enhanced user experience  
âœ… **System Health Monitoring** - Track resource usage with the `/usage` command  
âœ… **Extensible Modular Design** - Easily add support for additional platforms  
âœ… **Comprehensive Logging** - Detailed logs for both the bot and server components  

## **ğŸ“‚ Project Structure**

```
ScrapeGenie/
â”œâ”€â”€ backend/                # Backend API & Scrapers
â”‚   â”œâ”€â”€ routes/             # Express API routes
â”‚   â”‚   â”œâ”€â”€ aiRoutes.js     # AI-related routes
â”‚   â”‚   â””â”€â”€ scrape.js       # Scraping endpoints
â”‚   â”œâ”€â”€ scraper/            # Specialized scraping modules
â”‚   â”‚   â”œâ”€â”€ browserManager.js # Browser instance management
â”‚   â”‚   â”œâ”€â”€ helpers.js      # Scraper utility functions
â”‚   â”‚   â”œâ”€â”€ instaScraper.js # Instagram-specific scraper
â”‚   â”‚   â”œâ”€â”€ metadata.js     # Metadata extraction tools
â”‚   â”‚   â”œâ”€â”€ scraper.js      # Core scraping logic
â”‚   â”‚   â””â”€â”€ ytScraper.js    # YouTube-specific scraper
â”‚   â”œâ”€â”€ utils/              # Helper functions
â”‚   â”‚   â””â”€â”€ helpers.js      # General utility functions
â”‚   â”œâ”€â”€ README.md           # Backend documentation
â”‚   â””â”€â”€ server.js           # Main Express server
â”‚
â”œâ”€â”€ bot/                    # Telegram Bot
â”‚   â”œâ”€â”€ bot.js              # Bot initialization
â”‚   â”œâ”€â”€ commands.js         # Command handlers
â”‚   â”œâ”€â”€ messageHandler.js   # URL processing & formatting
â”‚   â”œâ”€â”€ logger.js           # Bot-specific logging
â”‚   â””â”€â”€ README.md           # Bot documentation
â”‚
â”œâ”€â”€ logs/                   # Application logs
â”‚   â”œâ”€â”€ bot.log             # Telegram bot logs
â”‚   â””â”€â”€ server.log          # Backend server logs
â”‚
â”œâ”€â”€ .env                    # Environment configuration
â”œâ”€â”€ example.env             # Example environment variables
â”œâ”€â”€ install.sh              # Installation script
â”œâ”€â”€ package.json            # Project dependencies
â”œâ”€â”€ LICENSE                 # GNU AGPL v3 License
â””â”€â”€ README.md               # Main documentation
```

## **âš™ï¸ Installation**

### **Automatic Installation**

For a quick setup, use the provided installation script:

```sh
git clone <repository-url>
cd ScrapeGenie
chmod +x install.sh
./install.sh
```

### **Manual Installation**

1. **Clone the Repository**
   ```sh
   git clone <repository-url>
   cd ScrapeGenie
   ```

2. **Install Dependencies**
   ```sh
   npm install
   ```

3. **Configure Environment Variables**
   ```sh
   cp example.env .env
   # Edit .env with your configuration
   ```

## **ğŸ”§ Configuration**

Open `.env` and configure the following parameters:

```env
# Required Settings
TELEGRAM_BOT_TOKEN=your-telegram-bot-token
PORT=5000

# Optional Settings
LOG_LEVEL=info                 # debug, info, warn, error
MAX_BROWSER_INSTANCES=3        # Number of concurrent browser instances
SCRAPE_TIMEOUT=30000           # Timeout in milliseconds
ENABLE_AI_FEATURES=false       # Enable AI-enhanced scraping
```

## **ğŸš€ Running the Application**

### **Start the Backend Server**

```sh
npm run start:server
# or
node backend/server.js
```

### **Start the Telegram Bot**

```sh
npm run start:bot
# or
node bot/bot.js
```

### **Run Both Components**

```sh
npm run start
```

## **ğŸ“± Using the Telegram Bot**

1. Start a chat with your bot on Telegram (@YourBotUsername)
2. Send a URL from YouTube, Instagram, or any website
3. The bot will extract and display the content in a nicely formatted message
4. Use the inline buttons to access additional features

### **Available Commands**

- `/start` - Introduction to the bot
- `/help` - Display available commands
- `/usage` - Check system resource usage
- `/about` - Information about ScrapeGenie

## **ğŸ§© API Endpoints**

The backend server exposes the following API endpoints:

- `POST /api/scrape` - Scrape content from a URL
- `GET /api/status` - Check the server status
- `POST /api/analyze` - AI-enhanced content analysis (if enabled)

## **ğŸ” How It Works**

1. When a URL is sent to the bot, it forwards the request to the backend
2. The backend identifies the URL type and selects the appropriate scraper
3. Puppeteer or Axios is used to fetch and extract the data
4. The extracted metadata is formatted and returned to the bot
5. The bot presents the information in a user-friendly format

## **ğŸ”§ Development**

### **Running in Development Mode**

```sh
npm run dev:server  # Start backend with hot-reload
npm run dev:bot     # Start bot with hot-reload
```

### **Testing**

```sh
npm test
```

### **Adding a New Scraper**

1. Create a new scraper file in `backend/scraper/`
2. Implement the scraping logic following the existing patterns
3. Register the new scraper in `backend/scraper/scraper.js`
4. Update the URL detection logic in the message handler

## **ğŸš€ Future Enhancements**

- **Additional Platform Support**: Twitter, TikTok, Reddit, Pinterest
- **Media Download Options**: Direct download for images and videos
- **Content Summarization**: AI-powered summary of long articles
- **Search Functionality**: Search for content by keywords
- **User Preferences**: Customizable output formats and settings
- **Scheduled Scraping**: Monitor URLs for changes
- **Batch Processing**: Handle multiple URLs at once
- **Authentication Support**: Access content behind login walls
- **Webhook Integration**: Connect with other services
- **Advanced Caching**: Efficient storage and retrieval of scraped content

## **ğŸ“„ License**

This project is licensed under the GNU AFFERO GENERAL PUBLIC LICENSE Version 3.

## **ğŸ¤ Contributing**

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

**Made with â¤ï¸ by Praveen Zalaki**